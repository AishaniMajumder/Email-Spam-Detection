{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dnh52OtsAyuu",
        "outputId": "5f59c2b8-1471-44de-bdd5-5581a1276e0d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.26.4)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.5.2)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.13.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.5.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2024.9.11)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.66.5)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n"
          ]
        }
      ],
      "source": [
        " pip install pandas numpy scikit-learn nltk\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "import re\n"
      ],
      "metadata": {
        "id": "6KYwdmnkBIDP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the dataset\n",
        "data = pd.read_csv('spam.csv', encoding='latin-1')\n",
        "\n",
        "# Display the first few rows of the dataset\n",
        "print(data.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fxaViU7aDMkT",
        "outputId": "c26cc579-5ae5-4b61-ce72-81075097ea1d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     v1                                                 v2 Unnamed: 2  \\\n",
            "0   ham  Go until jurong point, crazy.. Available only ...        NaN   \n",
            "1   ham                      Ok lar... Joking wif u oni...        NaN   \n",
            "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...        NaN   \n",
            "3   ham  U dun say so early hor... U c already then say...        NaN   \n",
            "4   ham  Nah I don't think he goes to usf, he lives aro...        NaN   \n",
            "\n",
            "  Unnamed: 3 Unnamed: 4  \n",
            "0        NaN        NaN  \n",
            "1        NaN        NaN  \n",
            "2        NaN        NaN  \n",
            "3        NaN        NaN  \n",
            "4        NaN        NaN  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **DATA PREPROCESSING**"
      ],
      "metadata": {
        "id": "z2CfzEwmGyOW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the dataset\n",
        "data = pd.read_csv('spam.csv', encoding='latin-1')\n",
        "\n",
        "# Get the actual column names\n",
        "actual_column_names = data.columns[:2]  # Get the names of the first two columns\n",
        "\n",
        "# Select and rename the columns\n",
        "data = data[actual_column_names]\n",
        "data.columns = ['label', 'message']  # Rename to 'label' and 'message'\n",
        "\n",
        "# Check for missing values\n",
        "print(data.isnull().sum())\n",
        "\n",
        "# Map labels to numerical values using .loc, handling potential errors\n",
        "data.loc[:, 'label'] = data['label'].map({'ham': 0, 'spam': 1}).fillna(-1).astype(int)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U_XoNZwADXGh",
        "outputId": "20aeac46-df08-4c73-e37f-98a3171ca194"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "label      0\n",
            "message    0\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **TEXT PREPROCESSING**"
      ],
      "metadata": {
        "id": "oqdGeTTFG4hb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('stopwords')  # Download stopwords if you haven't already\n",
        "\n",
        "# Function to preprocess the text\n",
        "def preprocess_text(text):\n",
        "    text = text.lower()  # Convert to lowercase\n",
        "    text = re.sub(r'\\W', ' ', text)  # Remove punctuation\n",
        "    text = re.sub(r'\\s+', ' ', text)  # Remove extra spaces\n",
        "    text = re.sub(r'\\d+', '', text)  # Remove digits\n",
        "    return text\n",
        "\n",
        "# Apply preprocessing\n",
        "data['message'] = data['message'].apply(preprocess_text)\n",
        "\n",
        "# Remove stop words\n",
        "stop_words = set(stopwords.words('english'))\n",
        "data['message'] = data['message'].apply(lambda x: ' '.join([word for word in x.split() if word not in stop_words]))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c26clahcHG1_",
        "outputId": "ec3e0b95-8743-4c0b-ac9d-f79a7a976f4e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Feature Extraction**"
      ],
      "metadata": {
        "id": "lEtR0_csHUsF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split # Import the missing function\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(data['message'], data['label'], test_size=0.2, random_state=42)\n",
        "\n",
        "# Initialize CountVectorizer\n",
        "vectorizer = CountVectorizer()\n",
        "\n",
        "# Fit and transform the training data\n",
        "X_train_vec = vectorizer.fit_transform(X_train)\n",
        "\n",
        "# Transform the testing data\n",
        "X_test_vec = vectorizer.transform(X_test)\n"
      ],
      "metadata": {
        "id": "U9xN3c_qHao_"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **TRAIN THE MODEL** (Naive Bayes)"
      ],
      "metadata": {
        "id": "PmpHazNzH4j6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "\n",
        "# Assuming 'data' is your DataFrame\n",
        "\n",
        "# ... (your existing preprocessing code) ...\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(data['message'], data['label'], test_size=0.2, random_state=42)\n",
        "\n",
        "# Check for NaN values in y_train and handle them\n",
        "if y_train.isnull().any():\n",
        "    # Option 1: Remove rows with NaN values in y_train\n",
        "    # X_train = X_train[y_train.notna()]\n",
        "    # y_train = y_train[y_train.notna()]\n",
        "\n",
        "    # Option 2: Impute NaN values with a suitable strategy (e.g., mean, median, mode)\n",
        "    # If 'label' is numerical:\n",
        "    # y_train = y_train.fillna(y_train.mean())  # Replace with appropriate imputation strategy\n",
        "    # If 'label' is categorical:\n",
        "    # Check if the mode series is empty before accessing it\n",
        "    if not y_train.mode().empty:\n",
        "        y_train = y_train.fillna(y_train.mode()[0])  # Replace with appropriate imputation strategy\n",
        "    else:\n",
        "        # Handle the case where mode is empty, e.g., impute with a default value\n",
        "        y_train = y_train.fillna('unknown')  # Or any other suitable value\n",
        "\n",
        "# Initialize CountVectorizer\n",
        "# ... (rest of your code) ..."
      ],
      "metadata": {
        "id": "iYK4GynXH_uW"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Evaluate the Model**"
      ],
      "metadata": {
        "id": "6eMFO_LJIuvG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "\n",
        "# Assuming 'data' is your DataFrame\n",
        "\n",
        "# ... (your existing preprocessing code) ...\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(data['message'], data['label'], test_size=0.2, random_state=42)\n",
        "\n",
        "# Check for NaN values in y_train and y_test and handle them\n",
        "# For y_train\n",
        "if y_train.isnull().any():\n",
        "    # Choose one of the options below:\n",
        "    # Option 1: Remove rows with NaN values in y_train\n",
        "    # X_train = X_train[y_train.notna()] # This line is causing the issue if all rows have NaN in y_train or y_test\n",
        "    # y_train = y_train[y_train.notna()] # This line is causing the issue if all rows have NaN in y_train or y_test\n",
        "\n",
        "    # Option 2: Impute NaN values with a suitable strategy (e.g., mode)\n",
        "    # If 'label' is categorical:\n",
        "    if not y_train.mode().empty:\n",
        "        y_train = y_train.fillna(y_train.mode()[0])\n",
        "    else:\n",
        "        y_train = y_train.fillna('unknown')\n",
        "\n",
        "# For y_test\n",
        "if y_test.isnull().any():\n",
        "    # Choose one of the options below:\n",
        "    # Option 1: Remove rows with NaN values in y_test\n",
        "    # X_test = X_test[y_test.notna()] # This line is causing the issue if all rows have NaN in y_train or y_test\n",
        "    # y_test = y_test[y_test.notna()] # This line is causing the issue if all rows have NaN in y_train or y_test\n",
        "\n",
        "    # Option 2: Impute NaN values with a suitable strategy (e.g., mode)\n",
        "    # If 'label' is categorical:\n",
        "    if not y_test.mode().empty:\n",
        "       y_test = y_test.fillna(y_test.mode()[0])\n",
        "    else:\n",
        "       y_test = y_test.fillna('unknown')\n",
        "\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(data['message'], data['label'], test_size=0.2, random_state=42)\n",
        "\n",
        "# Check for NaN values in y_train and y_test and handle them\n",
        "# For y_train\n",
        "if y_train.isnull().any():\n",
        "    # Choose one of the options below:\n",
        "    # Option 1: Remove rows with NaN values in y_train\n",
        "    # X_train = X_train[y_train.notna()] # This line is causing the issue if all rows have NaN in y_train or y_test\n",
        "    # y_train = y_train[y_train.notna()] # This line is causing the issue if all rows have NaN in y_train or y_test\n",
        "\n",
        "    # Option 2: Impute NaN values with a suitable strategy (e.g., mode)\n",
        "    # If 'label' is categorical:\n",
        "    if not y_train.mode().empty:\n",
        "        y_train = y_train.fillna(y_train.mode()[0])\n",
        "    else:\n",
        "        y_train = y_train.fillna('unknown')\n",
        "\n",
        "# For y_test\n",
        "if y_test.isnull().any():\n",
        "    # Choose one of the options below:\n",
        "    # Option 1: Remove rows with NaN values in y_test\n",
        "    # X_test = X_test[y_test.notna()] # This line is causing the issue if all rows have NaN in y_train or y_test\n",
        "    # y_test = y_test[y_test.notna()] # This line is causing the issue if all rows have NaN in y_train or y_test\n",
        "\n",
        "    # Option 2: Impute NaN values with a suitable strategy (e.g., mode)\n",
        "    # If 'label' is categorical:\n",
        "    if not y_test.mode().empty:\n",
        "       y_test = y_test.fillna(y_test.mode()[0])\n",
        "    else:\n",
        "       y_test = y_test.fillna('unknown')\n",
        "\n",
        "# Convert y_train and y_test to numerical type if needed\n",
        "# Assuming 'label' is a categorical column with values like 0, 1, etc.\n",
        "y_train = pd.to_numeric(y_train, errors='coerce').astype(int)  # Convert to numeric, handle errors\n",
        "y_test = pd.to_numeric(y_test, errors='coerce').astype(int)    # Convert to numeric, handle errors\n",
        "\n",
        "# Initialize CountVectorizer\n",
        "vectorizer = CountVectorizer()\n",
        "\n",
        "# Fit and transform the training data\n",
        "X_train_vec = vectorizer.fit_transform(X_train)\n",
        "\n",
        "# Transform the testing data\n",
        "X_test_vec = vectorizer.transform(X_test)\n",
        "\n",
        "# Initialize the MultinomialNB model\n",
        "model = MultinomialNB()\n",
        "\n",
        "# Fit the model to the training data\n",
        "model.fit(X_train_vec, y_train)\n",
        "\n",
        "# Make predictions\n",
        "y_pred = model.predict(X_test_vec)\n",
        "\n",
        "# Print the classification report\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "# Print the confusion matrix\n",
        "print(confusion_matrix(y_test, y_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mvmGq4WWJCbC",
        "outputId": "17516431-46b6-4d70-dbf4-7c16b82df0ba"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      1.00      0.99       965\n",
            "           1       0.99      0.89      0.94       150\n",
            "\n",
            "    accuracy                           0.98      1115\n",
            "   macro avg       0.98      0.95      0.96      1115\n",
            "weighted avg       0.98      0.98      0.98      1115\n",
            "\n",
            "[[963   2]\n",
            " [ 16 134]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "import re\n",
        "\n",
        "# Load the dataset\n",
        "data = pd.read_csv('spam.csv', encoding='latin-1')\n",
        "data = data[['v1', 'v2']]\n",
        "data.columns = ['label', 'message']\n",
        "data['label'] = data['label'].map({'ham': 0, 'spam': 1})\n",
        "\n",
        "# Preprocess the text\n",
        "nltk.download('stopwords')\n",
        "def preprocess_text(text):\n",
        "    text = text.lower()\n",
        "    text = re.sub(r'\\W', ' ', text)\n",
        "    text = re.sub(r'\\s+', ' ', text)\n",
        "    text = re.sub(r'\\d+', '', text)\n",
        "    return text\n",
        "\n",
        "data['message'] = data['message'].apply(preprocess_text)\n",
        "stop_words = set(stopwords.words('english'))\n",
        "data['message'] = data['message'].apply(lambda x: ' '.join([word for word in x.split() if word not in stop_words]))\n",
        "\n",
        "# Split the dataset\n",
        "X_train, X_test, y_train, y_test = train_test_split(data['message'], data['label'], test_size=0.2, random_state=42)\n",
        "\n",
        "# Feature extraction\n",
        "vectorizer = CountVectorizer()\n",
        "X_train_vec = vectorizer.fit_transform(X_train)\n",
        "X_test_vec = vectorizer.transform(X_test)\n",
        "\n",
        "# Train the model\n",
        "model = MultinomialNB()\n",
        "model.fit(X_train_vec, y_train)\n",
        "\n",
        "# Evaluate the model\n",
        "y_pred = model.predict(X_test_vec)\n",
        "print(classification_report(y_test, y_pred))\n",
        "print(confusion_matrix(y_test, y_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FM7AQ_jjKAfU",
        "outputId": "251a0d35-a0cd-4e0a-ccd8-f19441ea8a20"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      0.99      0.99       965\n",
            "           1       0.94      0.91      0.93       150\n",
            "\n",
            "    accuracy                           0.98      1115\n",
            "   macro avg       0.97      0.95      0.96      1115\n",
            "weighted avg       0.98      0.98      0.98      1115\n",
            "\n",
            "[[957   8]\n",
            " [ 14 136]]\n"
          ]
        }
      ]
    }
  ]
}